# ğŸ§  Corrective Retrieval-Augmented Generation (CRAG)

<p align="center">

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Paper](https://img.shields.io/badge/Paper-arXiv%3A2401.15884-red.svg)
![Provider](https://img.shields.io/badge/Provider-Groq%20%7C%20OpenAI-purple.svg)
![Vector Store](https://img.shields.io/badge/VectorStore-FAISS-orange.svg)
![Framework](https://img.shields.io/badge/Framework-LangGraph-black.svg)

</p>

<p align="center">
<b>Modular, Provider-Agnostic Implementation of Corrective RAG</b><br>
Based on the paper:<br>
ğŸ“„ <a href="https://arxiv.org/pdf/2401.15884">Corrective Retrieval Augmented Generation (CRAG)</a>
</p>

---

## ğŸ¯ Overview

This repository implements a **self-correcting Retrieval-Augmented Generation (RAG) pipeline** that evaluates retrieval quality and dynamically applies corrective strategies before answer generation.

Unlike naÃ¯ve RAG systems, this CRAG implementation:

- âœ… Evaluates each retrieved document using an LLM-based scoring mechanism  
- âœ… Classifies retrieval into **CORRECT / AMBIGUOUS / INCORRECT**  
- âœ… Dynamically rewrites queries when needed  
- âœ… Augments evidence using web search (Tavily)  
- âœ… Performs sentence-level knowledge refinement  
- âœ… Supports both **Groq** and **OpenAI** providers  
- âœ… Runs from a single modular Python file  

---

# ğŸ— Architecture

<p align="center">
  <img src="docs/crag_diagram.png" width="850">
</p>

---

## ğŸ” High-Level Pipeline

```
User Query
     â†“
Recursive PDF Loader
     â†“
Text Chunking (RecursiveCharacterTextSplitter)
     â†“
Vector Indexing (FAISS)
     â†“
Retriever (Top-k Similarity Search)
     â†“
LLM-based Document Evaluation
     â†“
Conditional Routing:
    â”œâ”€â”€ CORRECT
    â”‚     â†’ Internal Knowledge Refinement
    â”‚     â†’ Generate Answer
    â”‚
    â”œâ”€â”€ AMBIGUOUS
    â”‚     â†’ Query Rewrite
    â”‚     â†’ Web Search (Tavily)
    â”‚     â†’ Merge Internal + Web
    â”‚     â†’ Sentence Filtering
    â”‚     â†’ Generate Answer
    â”‚
    â””â”€â”€ INCORRECT
          â†’ Query Rewrite
          â†’ Web Search
          â†’ Replace Evidence
          â†’ Sentence Filtering
          â†’ Generate Answer
```

This routing logic is the core innovation introduced in the CRAG paper.

---

# ğŸ“‚ Repository Structure

```
CRAG/
â”‚
â”œâ”€â”€ corrective_rag_multi_provider.py
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ book1.pdf
â”‚   â”œâ”€â”€ book2.pdf
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ crag_diagram.png
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

- All PDFs inside `/documents` are loaded **recursively**
- The entire pipeline runs from one modular Python file

---

# âš™ï¸ Supported Execution Modes

Provider selection is controlled via environment variables.

---

## ğŸŸ£ Groq Mode (Recommended â€“ Fast & Cost Efficient)

```bash
export LLM_PROVIDER=groq
export GROQ_API_KEY=your_groq_key
export TAVILY_API_KEY=your_tavily_key
python corrective_rag_multi_provider.py
```

Embeddings:
- Local SentenceTransformers (`all-MiniLM-L6-v2`)

Best for:
- Fast experimentation
- Low cost
- High throughput

---

## ğŸ”µ OpenAI Mode

```bash
export LLM_PROVIDER=openai
export OPENAI_API_KEY=your_openai_key
export TAVILY_API_KEY=your_tavily_key
python corrective_rag_multi_provider.py
```

Embeddings:
- `text-embedding-3-large`

Best for:
- High-quality evaluation
- Controlled benchmarking

---

# ğŸ“¦ Installation

## 1ï¸âƒ£ Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

---

## 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### Required Packages

```
langchain
langchain-community
langchain-openai
langchain-groq
langchain-huggingface
langchain-text-splitters
langgraph
faiss-cpu
pypdf
sentence-transformers
torch
python-dotenv
tavily-python
```

---

# â–¶ï¸ Running the System

```bash
python corrective_rag_multi_provider.py
```

You will be prompted:

```
Enter your question:
```

Example:

```
cricket match total overs in one day international
```

---

# ğŸ§  Core Components

| Component | Responsibility |
|------------|---------------|
| Recursive PDF Loader | Recursively loads all PDFs from `/documents` |
| Vector Retriever | Chunking + FAISS indexing |
| Retrieval Evaluator | LLM-based scoring of each chunk |
| Query Rewriter | Converts question into search query |
| Web Search Node | Fetches external evidence using Tavily |
| Knowledge Refinement | Sentence-level filtering using LLM |
| Answer Generator | Produces grounded final response |
| LangGraph Router | Controls conditional execution flow |

---

# ğŸ”¬ Retrieval Evaluation Logic

Thresholds:

```
UPPER_TH = 0.7
LOWER_TH = 0.3
```

Verdict conditions:

| Condition | Verdict |
|------------|---------|
| Any score > 0.7 | CORRECT |
| All scores < 0.3 | INCORRECT |
| Otherwise | AMBIGUOUS |

---

# ğŸ§ª Debug Transparency

The system prints:

- Retrieval stage
- Document scoring
- Routing decision
- Web query
- Sentence filtering progress
- Final verdict
- Total latency

This ensures full observability of the corrective process.

---

# ğŸ”¬ Research Alignment

This implementation operationalizes the CRAG paper by implementing:

- Retrieval quality evaluation
- Conditional correction routing
- Knowledge decomposition
- Sentence-level filtering
- Web augmentation
- Generator-level synthesis over corrected evidence

It translates the research architecture into a fully runnable modular system.

---

# âš ï¸ Limitations

- Sentence filtering is sequential (may increase latency)
- No hybrid BM25 integration yet
- No cross-encoder reranking
- No citation-level grounding
- No hallucination risk scoring

The architecture is modular and extensible.

---

# ğŸš€ Potential Extensions

- Hybrid BM25 + Dense Retrieval
- Reciprocal Rank Fusion (RRF)
- Cross-Encoder Reranking
- Structured JSON Output Mode
- Confidence Scoring
- Hallucination Risk Estimation
- Async Parallel Filtering
- FastAPI Deployment

---

# ğŸ“˜ Citation

If using this repository, please cite:

```
@article{yan2024corrective,
  title={Corrective Retrieval Augmented Generation},
  author={Yan et al.},
  year={2024}
}
```

Paper:
https://arxiv.org/abs/2401.15884

---

# ğŸ“œ License

MIT License

---

# ğŸ Summary

This repository demonstrates how to evolve from naÃ¯ve RAG into a:

> **Self-evaluating, dynamically routed, corrective retrieval-augmented generation system.**

CRAG transforms passive retrieval into an actively verified reasoning pipeline.